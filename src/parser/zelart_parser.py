import requests
from bs4 import BeautifulSoup
import json
import os
import urllib3

class PrestaShopScraper:
    def __init__(self):
        self.email = os.environ["LOGIN"]
        self.password = os.environ["PASSWORD"]

        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        self.login_url = "https://zelart.com.ua/user/login"

        self.session = requests.Session()

    def login(self):
        """Log in to the website and store the session."""
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Content-Type": "application/x-www-form-urlencoded",
            "Referer": self.login_url,
            "Origin": "https://zelart.com.ua"
        }
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ–≥–∏–Ω–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è CSRF-—Ç–æ–∫–µ–Ω–∞
        login_page = self.session.get(self.login_url, headers=headers, verify=False)
        soup = BeautifulSoup(login_page.text, "html.parser")
        
        # CSRF-—Ç–æ–∫–µ–Ω
        csrf_token = soup.find("input", {"name": "_csrf-frontend"})["value"]
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º POST-–∑–∞–ø—Ä–æ—Å —Å CSRF-—Ç–æ–∫–µ–Ω–æ–º
        payload = {
            "LoginForm[login]": self.email,  # –ü–æ–ª–µ –¥–ª—è email
            "LoginForm[password]": self.password,  # –ü–æ–ª–µ –¥–ª—è –ø–∞—Ä–æ–ª—è
            "LoginForm[rememberMe]": "1",  # –ó–∞–ø–æ–º–Ω–∏—Ç—å –º–µ–Ω—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            "_csrf-frontend": csrf_token  # CSRF-—Ç–æ–∫–µ–Ω
        }

        try:
            response = self.session.post(self.login_url, data=payload, headers=headers, verify=False)
            if response.status_code == 200 and "logout" in response.text.lower():
                print("‚úÖ Login successful")
            else:
                print("‚ùå Login failed. Check your credentials or login URL.")
        except requests.exceptions.RequestException as e:
            print(f"Login error: {e}")


    def fetch_page(self, url):
        """Fetch the HTML content of a product page."""
        headers = {"User-Agent": "Mozilla/5.0"}
        try:
            response = self.session.get(url, headers=headers, verify=False)
            if response.status_code == 200:
                return response.text
            else:
                print(f"Failed to fetch {url} - Status Code: {response.status_code}")
                return None
        except requests.exceptions.SSLError as e:
            print(f"SSL error for {url}: {e}")
            return None
        

    def parse_product(self, url: str) -> dict | None:
        """Extract title, price, and description from a product page."""
        html = self.fetch_page(url)
        print("üêç html: ", html)

        if not html:
            print(f"No HTML found!")
            return None

        soup = BeautifulSoup(html, "html.parser")

        app_component = soup.find(class_= 'app-component')
        json_data = f'''{app_component["data-init-data"]}'''
        data = json.loads(json_data)
        
        product_info = {
            "id": data['product']['id'],
            "title": data['model']['title'],
            "priceCur": data['product']['priceCur'],
            "priceWithDiscount": data['product']['priceWithDiscount'],
            "priceSrp": data['product']['priceSrp'],
            "isHidden": data['product']['isHidden'],
            "url": url
        }

        return product_info


    def scrape_product(self, url):
        """ Scrape product information (Do not use this with loops, use login() + parse_product(), only use this for a single product) """
        self.login()
        product = self.parse_product(url)
        return product